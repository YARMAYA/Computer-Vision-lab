Experiment 1: Image and Video Reading & Display
This experiment focuses on image acquisition and video capture. Images are read in multiple modes (grayscale, color, unchanged), and live video is captured using a camera. The video stream is displayed in real time and stored for further analysis.

Experiment 2: Image Transformations
Geometric transformations such as scaling, translation, and rotation are implemented. The experiment demonstrates how spatial manipulation affects image structure and visual appearance.

Experiment 3: Histogram Analysis
In this experiment, histograms of grayscale images are computed and plotted. Histogram equalization is applied to enhance image contrast and improve visual quality.

Experiment 4: Edge Detection
Edge detection is performed using the Canny edge detection algorithm, highlighting object boundaries and structural information in images.

Experiment 5: Image Enhancement
Spatial domain filtering techniques such as smoothing (noise reduction) and sharpening (edge enhancement) are applied to improve image quality.

Experiment 6: Convolution, Filtering, and Motion Blur
This experiment demonstrates convolution-based filtering and simulates motion blur, helping to understand degradation models in digital imaging.

Experiment 7: Corner Detection
Feature detection is carried out using Harris Corner Detection and SIFT (Scale-Invariant Feature Transform) to identify key points in images.

Experiment 8: Texture Segmentation using Gabor Filters
A bank of Gabor filters is used to analyze texture patterns and perform texture-based image segmentation.

Experiment 9: Image Segmentation
Both classical segmentation techniques (thresholding, region-based methods) and learning-based approaches are implemented and compared on natural images.

Experiment 10: Object Detection
Object detection is performed using traditional computer vision techniques and modern deep learning-based methods, highlighting accuracy, robustness, and performance differences.
